{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcellinus-witarsah/titanic-survival-model/blob/main/titanic-survival-model-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic Survival Model\n",
        "\n",
        "![titanic_image](https://upload.wikimedia.org/wikipedia/commons/6/6e/St%C3%B6wer_Titanic.jpg)\n",
        "\n",
        "\n",
        "This Project is aimed to create a model which can predict if a passenger survived a Titanic accident based on their data which consist of:\n",
        "1.  PassengerId  (int64)  \n",
        "2.  Survived     (int64)  \n",
        "3.  Pclass       (int64)\n",
        "4.  Name         (object)\n",
        "5.  Sex          (object)\n",
        "6.  Age          (float64)\n",
        "7.  SibSp        (int64) \n",
        "8.  Parch        (int64)\n",
        "9.  Ticket       (object) \n",
        "10. Fare         (float64)\n",
        "11. Cabin        (object) \n",
        "12. Embarked     (object)\n",
        "\n",
        "The outline of this project will consists of:\n",
        "1. Data Preparation\n",
        "2. Exploratory Data Analysis\n",
        "3. Data Preprocessing and Feature Engineering\n",
        "4. Modelling\n",
        "5. Evaluation\n",
        "6. Submission to Kaggle.\n",
        "\n",
        "This project is based on competition being held on Kaggle which can be access using this link https://www.kaggle.com/c/titanic.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hNONTFqwV-TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "The data it self can be downloaded from Kaggle using which can be accessed using this link https://www.kaggle.com/c/titanic/data. But, the data had already been provided from my Github, therefore the link of the raw data already provided which can be accessed using pandas library. These are the links for:\n",
        "1. Train data ('https://raw.githubusercontent.com/marcellinus-witarsah/dataScienceMiniProjects/main/TitanicSurvivalModel/train.csv')\n",
        "2. Test data ('https://raw.githubusercontent.com/marcellinus-witarsah/dataScienceMiniProjects/main/TitanicSurvivalModel/test.csv')"
      ],
      "metadata": {
        "id": "w4GqJES_iEWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "jMxfLULEMfja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data frame for original data\n",
        "titanic_train_ori = pd.read_csv('https://raw.githubusercontent.com/marcellinus-witarsah/dataScienceMiniProjects/main/TitanicSurvivalModel/train.csv')\n",
        "titanic_test_ori = pd.read_csv('https://raw.githubusercontent.com/marcellinus-witarsah/dataScienceMiniProjects/main/TitanicSurvivalModel/test.csv')\n",
        "\n",
        "# data frame from editing\n",
        "titanic_train = titanic_train_ori.copy()\n",
        "titanic_test = titanic_test_ori.copy()\n",
        "titanic_train['train_test'] = 0\n",
        "titanic_test['train_test'] = 1\n",
        "\n",
        "titanic_all_ori = pd.concat([titanic_train, titanic_test], ignore_index=True) \n",
        "titanic_all = titanic_all_ori.copy()\n",
        "\n",
        "pd.set_option('display.max_rows', titanic_train.shape[0])"
      ],
      "metadata": {
        "id": "23cuQ0URkuCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IQvSdhHyMfjc"
      },
      "outputs": [],
      "source": [
        "# check the all data\n",
        "display(titanic_all.info())\n",
        "display(titanic_all.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There 4 columns in training data that contains missing data which are Age, Fare, Cabin and Embarked. Survived has missing data because it is a testing data which we want to predict using the model."
      ],
      "metadata": {
        "id": "3XUCRztiJC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_count = []\n",
        "missing_percent = []\n",
        "col_names = titanic_all.columns\n",
        "\n",
        "for col in col_names:\n",
        "  missing_count.append(titanic_all[col].isna().sum())\n",
        "  missing_percent.append(titanic_all[col].isna().sum()/len(titanic_all)*100)\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Column': col_names,\n",
        "    'MissingCount': missing_count,\n",
        "    'MissingPercent%': missing_percent\n",
        "})"
      ],
      "metadata": {
        "id": "TCIMLQyzpNTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkVXW1kUMfjd"
      },
      "source": [
        "We might be considering to drop 'Cabin' Column because there's so many missing values about 77% (train) and 78% (test)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with Missing Data (Data Preprocessing)\n",
        "\n"
      ],
      "metadata": {
        "id": "yZOjvSDBJwAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "fVg_wnNzupZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Age\n",
        "Before starting, there are some missing data that needs to be handled. Therefore it must be filled with mean of age from all data. But this approach is not suggested because it doesn't preserve the relationship between data. There might be misfilled on an old person 80 years of age with 45 years. In saving passenger, we both know that the oldest passenger is prioritized.  \n",
        "\n",
        "the details are already there within the name of the passenger. We can apply **educated guessing** based on their title like Mr., Mrs, Ms., etc. \n",
        "\n",
        "We will group all passenger who has the same title and compute the mean. Then, we can impute to the missing data in \"Age\" column."
      ],
      "metadata": {
        "id": "EefHNuiYKE9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Distribution of Age')\n",
        "sns.distplot(x=titanic_all['Age'], hist=False) \n",
        "display(titanic_all.describe()['Age'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zQNZI85HKTgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_age = {}\n",
        "unique_titles = titanic_all['Name'] \\\n",
        "                .apply(lambda x: x.split(',')[1].split('.')[0].strip()).unique()\n",
        "\n",
        "for title in unique_titles:\n",
        "  title_age[title] = float(titanic_all.loc[\n",
        "      titanic_all['Name'] \\\n",
        "      .apply(lambda x: x.split(',')[1].split('.')[0].strip()) == title, 'Age'] \\\n",
        "      .mean() \\\n",
        "      .round())\n",
        "\n",
        "titanic_all['Age'] = titanic_all.apply(lambda row: title_age[row['Name'].split(',')[1].split('.')[0].strip()] if np.isnan(row['Age']) else row['Age'], axis=1)"
      ],
      "metadata": {
        "id": "QFtm7gNAx9wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cabin"
      ],
      "metadata": {
        "id": "1Z4sqNfrKIvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Cabin We might consider dropping it latter in Feature Engineering Section because the missing data is to much (**above 75%** missing for either train and test data)\n",
        "\n",
        "There might be an alternative which is we can just fill it based on fare. "
      ],
      "metadata": {
        "id": "gOe06bv1bfEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace Nan or missing value with 'N' first\n",
        "titanic_train.loc[titanic_train['Cabin'].isna(), 'Cabin'] = 'N'\n",
        "titanic_test.loc[titanic_test['Cabin'].isna(), 'Cabin'] = 'N'\n",
        "\n",
        "# Adding new feature column with first letter in that Cabin Column\n",
        "titanic_train['CabinCode'] = titanic_train['Cabin'].apply(lambda x: str(x).split(' ')[0][0]).str.lower()\n",
        "titanic_test['CabinCode'] = titanic_test['Cabin'].apply(lambda x: str(x).split(' ')[0][0]).str.lower()\n",
        "\n",
        "# mean fare for each Cabin\n",
        "train_cabin_fare = titanic_train.groupby('CabinCode')['Fare'].mean()\n",
        "test_cabin_fare = titanic_test.groupby('CabinCode')['Fare'].mean()\n",
        "\n",
        "# count for each Cabin\n",
        "train_cabin_count = titanic_train.groupby('CabinCode')['Fare'].count()\n",
        "test_cabin_count = titanic_test.groupby('CabinCode')['Fare'].count()\n",
        "\n",
        "# datafram full of train and test mean and count\n",
        "cabin_count_fare = pd.concat(objs=[train_cabin_count, test_cabin_count, \n",
        "                                   train_cabin_fare, test_cabin_fare], \n",
        "                             keys=['TrainCount', 'TestCount', \n",
        "                                   'TrainFare', 'TestFare'], \n",
        "                             axis=1)\n",
        "cabin_count_fare['Cabin'] = train_cabin_count.index\n",
        "\n",
        "# Exclued cabin n (n=missing_value)\n",
        "cabin_count_fare_exclude_cabin_n = cabin_count_fare[cabin_count_fare['Cabin']!='n'] \n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10), nrows=2, ncols=2)\n",
        "# Cabin vs TrainCount/ TestCount\n",
        "ax[0][0].set_title('Train: Cabin vs TrainCount')\n",
        "sns.barplot(x='Cabin',\n",
        "            y='TrainCount',\n",
        "            data=cabin_count_fare_exclude_cabin_n,\n",
        "            ax=ax[0][0])\n",
        "\n",
        "ax[1][0].set_title('Test: Cabin vs TestCount')\n",
        "sns.barplot(x='Cabin',\n",
        "            y='TestCount', \n",
        "            data=cabin_count_fare_exclude_cabin_n,\n",
        "            ax=ax[1][0])\n",
        "\n",
        "# Cabin vs TrainCount/ TestCount\n",
        "ax[0][1].set_title('Train: Cabin vs TrainFare')\n",
        "sns.lineplot(x='Cabin',\n",
        "            y='TrainFare',\n",
        "            data=cabin_count_fare_exclude_cabin_n,\n",
        "            ax=ax[0][1])\n",
        "\n",
        "ax[1][1].set_title('Test: Cabin vs TestFare')\n",
        "sns.lineplot(x='Cabin',\n",
        "            y='TestFare', \n",
        "            data=cabin_count_fare_exclude_cabin_n,\n",
        "            ax=ax[1][1])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lgoVPnmDqgOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace Nan or missing value with 'N' first\n",
        "titanic_all.loc[titanic_all['Cabin'].isna(), 'Cabin'] = 'N'\n",
        "\n",
        "# Adding new feature column with first letter in that Cabin Column\n",
        "titanic_all['CabinCode'] = titanic_all['Cabin'].apply(lambda x: str(x).split(' ')[0][0]).str.lower()\n",
        "\n",
        "# mean fare for each Cabin\n",
        "all_cabin_fare = titanic_all.groupby('CabinCode')['Fare'].mean()\n",
        "\n",
        "# count for each Cabin\n",
        "all_cabin_count = titanic_all.groupby('CabinCode')['Fare'].count()\n",
        "\n",
        "# datafram full of train and test mean and count\n",
        "cabin_count_fare = pd.concat(objs=[all_cabin_count, all_cabin_fare], \n",
        "                             keys=['Count', 'Fare'], \n",
        "                             axis=1)\n",
        "cabin_count_fare['Cabin'] = all_cabin_count.index\n",
        "\n",
        "\n",
        "# Exclued cabin n (n=missing_value)\n",
        "cabin_count_fare_exclude_cabin_n = cabin_count_fare[cabin_count_fare['Cabin']!='n'] \n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10), ncols=2)\n",
        "\n",
        "# Cabin vs Count\n",
        "ax[0].set_title('Cabin vs TrainCount')\n",
        "sns.barplot(x='Cabin',\n",
        "            y='Count',\n",
        "            data=cabin_count_fare_exclude_cabin_n,\n",
        "            ax=ax[0])\n",
        "\n",
        "ax[1].set_title('Cabin vs TestCount')\n",
        "sns.lineplot(x='Cabin',\n",
        "            y='Fare', \n",
        "            data=cabin_count_fare_exclude_cabin_n,\n",
        "            ax=ax[1])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "RV3SCnAS1Nr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cabin_count_fare"
      ],
      "metadata": {
        "id": "0fbU1cwEYXSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than filling cabin value according to fare. Create a new feature column 'HasCabin' because the data is collected after accident. If the value of 'HasCabin' is 0 that means that the passenger might be dead because he can't report where the location of his cabin."
      ],
      "metadata": {
        "id": "xaDUkgotsWaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all['HasCabin'] = titanic_all['Cabin']\\\n",
        "                          .apply(lambda x: 0 if str(x)== 'N' else 1)\n"
      ],
      "metadata": {
        "id": "6LT6isi-YWjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(7,12), nrows=2)\n",
        "ax[0].set_title('HasCabin Count with Hue Survived')\n",
        "sns.countplot(x='HasCabin', hue='Survived',\n",
        "              data=titanic_all, ax=ax[0])\n",
        "\n",
        "ax[1].set_title('')\n",
        "sns.barplot(x='HasCabin', y='Survived', data=titanic_all, ax=ax[1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rxIWBfw-nuc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown above people that HasCabin value equals 1 has higher chance of surviving the titanic (from training data)."
      ],
      "metadata": {
        "id": "zFa-T-3Ry3FS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embarked\n",
        "Data that has missing value on Embarked column is on the train data. We can just need to replace it with data that is frequent on the column which is 'S' but we might have a chance of filling with a wrong value because embarked mean where the traveler got on board from. There might be a correlation between Fare and the location (Embarked) the passenger embarked and of course Pclass (represents socio-economic status or SES).\n",
        "\n",
        "We only need to find out the price (per person) to compare with other prices (per person) to allocate the missing embarked port."
      ],
      "metadata": {
        "id": "nAT5Rgn_KI39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new Column called FamilySize which indicates how many families they travelled with\n",
        "\n",
        "> ***FamilySize = Parch + SibSp + 1*** (+1 mean include the passenger itself)\n",
        "\n",
        "Create new Column called FriendSize which indicates how many families they travelled with\n",
        "\n",
        "> ***FriendSize = Count(PassengerID with same Ticket)***\n",
        "\n",
        "In the end we will create a GroupSize which filled with inferences of total group size that travelled with a passenger\n",
        "\n",
        "> ***FriendSize = Max(FamilySize, FriendSize)***\n",
        "\n",
        "Finally, to determine FarePerPerson will be computed like this\n",
        "\n",
        "> ***FarePerPerson = Fare/FriendSize***"
      ],
      "metadata": {
        "id": "Zldyhh4d4ihj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate FamilySize\n",
        "# # titanic_train['FamilySize'] = titanic_train['SibSp'] + titanic_train['Parch'] + 1\n",
        "# # titanic_test['FamilySize'] = titanic_test['SibSp'] + titanic_test['Parch'] + 1\n",
        "# titanic_test['FamilySize'] = titanic_test['SibSp'] + titanic_test['Parch'] + 1\n",
        "\n",
        "# # Calculate FriendSize for train\n",
        "# friend_size = titanic_train.groupby('Ticket')['PassengerId'].count()\n",
        "# for key, val in friend_size.items():\n",
        "#   titanic_train.loc[titanic_train['Ticket'] == key, 'FriendSize'] = val\n",
        "\n",
        "# # Calculate FriendSize for test\n",
        "# friend_size = titanic_test.groupby('Ticket')['PassengerId'].count()\n",
        "# for key, val in friend_size.items():\n",
        "#   titanic_test.loc[titanic_test['Ticket'] == key, 'FriendSize'] = val\n",
        "\n",
        "# # Find GroupSize\n",
        "# titanic_train['GroupSize'] = titanic_train[['FamilySize', 'FriendSize']].max(axis=1)\n",
        "# titanic_test['GroupSize'] = titanic_test[['FamilySize', 'FriendSize']].max(axis=1)\n",
        "\n",
        "# # Calculate FarePerPerson\n",
        "# titanic_train['FarePerPerson'] = titanic_train['Fare'] / titanic_train['FriendSize']\n",
        "# titanic_test['FarePerPerson'] = titanic_test['Fare'] / titanic_test['FriendSize']"
      ],
      "metadata": {
        "id": "-GILHCwhjz0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate FamilySize\n",
        "titanic_all['FamilySize'] = titanic_all['SibSp'] + titanic_all['Parch'] + 1\n",
        "\n",
        "# Calculate FriendSize\n",
        "friend_size = titanic_all.groupby('Ticket')['PassengerId'].count()\n",
        "for key, val in friend_size.items():\n",
        "  titanic_all.loc[titanic_all['Ticket'] == key, 'FriendSize'] = val\n",
        "\n",
        "\n",
        "# Find GroupSize\n",
        "titanic_all['GroupSize'] = titanic_all[['FamilySize', 'FriendSize']].max(axis=1)\n",
        "\n",
        "# Calculate FarePerPerson\n",
        "titanic_all['FarePerPerson'] = titanic_all['Fare'] / titanic_all['FriendSize']"
      ],
      "metadata": {
        "id": "_qYigvTR2op5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all.info()"
      ],
      "metadata": {
        "id": "aLuE2d7EwBTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to high standard deviation (above +2 or below -2), using mean for determining Embarked because the data is to far from the actual value (ouutlier)."
      ],
      "metadata": {
        "id": "wa28S1GVQkc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(pd.pivot_table(data=titanic_all, \n",
        "               index='Pclass', \n",
        "               columns='Embarked', \n",
        "               values='FarePerPerson', \n",
        "               aggfunc='median'))\n",
        "\n",
        "facet_grid_med = sns.FacetGrid(data=titanic_all, col='Pclass', \n",
        "                               sharey=False, sharex=False)\n",
        "facet_grid_med.map_dataframe(sns.barplot, \n",
        "                             x='Embarked', \n",
        "                             y='FarePerPerson', \n",
        "                             estimator=np.median)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E49-q5XdufPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the FarePerPerson is high on Pclass=1. Pclass=2 and Pclass3 (Embarked C) is higher other.\n"
      ],
      "metadata": {
        "id": "chCBHBVQF_ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_med = pd.pivot_table(data=titanic_all, \n",
        "               index='Pclass', \n",
        "               columns='Embarked', \n",
        "               values='FarePerPerson', \n",
        "               aggfunc='median')\n",
        "\n",
        "\n",
        "# df.medtitanic_train[titanic_train['Embarked'].isna()]\n",
        "# t = pd.DataFrame(df_med, index=df_med.index)\n",
        "# t[0]\n",
        "for i in df_med[df_med.index==1]:\n",
        "  print(i)\n",
        "  print(titanic_all.loc[titanic_all['Embarked'].isna(), 'FarePerPerson'] - df_med[df_med.index==1][i].values)"
      ],
      "metadata": {
        "id": "vZTLZvETLfnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill Embarked C on the missing value because it is close to FarePerPerson where Embarked is 'C'."
      ],
      "metadata": {
        "id": "Kr--I3o-WpLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all.loc[titanic_all['Embarked'].isna(), 'Embarked'] = 'C'"
      ],
      "metadata": {
        "id": "fEbOmkY_W5xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all.info()"
      ],
      "metadata": {
        "id": "W9zdI_1jWodf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display(pd.pivot_table(data=titanic_test, \n",
        "#                index='Pclass', \n",
        "#                columns='Embarked', \n",
        "#                values='FarePerPerson', \n",
        "#                aggfunc='median'))\n",
        "\n",
        "# facet_grid_med = sns.FacetGrid(data=titanic_test, col='Pclass', \n",
        "#                                sharey=False, sharex=False)\n",
        "# facet_grid_med.map_dataframe(sns.barplot, \n",
        "#                              x='Embarked', \n",
        "#                              y='FarePerPerson', \n",
        "#                              estimator=np.median)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "FSqJ32tYnPe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fare\n",
        "Simply fill it with mean of fare with the median where the passenger embarked"
      ],
      "metadata": {
        "id": "oItasBPbi0dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all[titanic_all['Fare'].isna()]"
      ],
      "metadata": {
        "id": "3PftQfB5nHQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all[titanic_all['Embarked']=='S']['FarePerPerson'].median()"
      ],
      "metadata": {
        "id": "AvrcqwHInb1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if titanic_all['Fare'].isna().sum() > 0:\n",
        "  titanic_all.loc[titanic_all['Fare'].isna(), ['Fare', 'FarePerPerson']] = titanic_all[titanic_all['Embarked']=='S']['FarePerPerson'].median() * titanic_all.loc[titanic_all['Fare'].isna(), 'FriendSize']"
      ],
      "metadata": {
        "id": "8B25h48si2cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(titanic_all.info())"
      ],
      "metadata": {
        "id": "ovtOCRs3sjRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElBOxSF_Mfje"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "This section contains data visualization and analysis to gain insights and characteristics of the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all.info()"
      ],
      "metadata": {
        "id": "r7q2AOmJKPve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Data That are Numeric"
      ],
      "metadata": {
        "id": "iHqHwHqaH7_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "b0YtxjpsMfje"
      },
      "outputs": [],
      "source": [
        "titanic_train = titanic_all[titanic_all['train_test']==0]\n",
        "titanic_test = titanic_all[titanic_all['train_test']==1]\n",
        "titanic_num = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FriendSize', 'GroupSize', 'FarePerPerson']\n",
        "\n",
        "fig, ax = plt.subplots(nrows=len(titanic_num), figsize=[7, len(titanic_num)*5])\n",
        "\n",
        "for i, col in enumerate(titanic_num):\n",
        "    sns.histplot(titanic_train[col], linewidth=0, ax=ax[i])\n",
        "    ax[i].set_title(col)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QafJQ4PFMfjf"
      },
      "source": [
        "Based on the distribution of the data we can see that 'SibSp', 'Parch', and 'Fare' columns are are right skewed. This probem will be solved using scaling or normalization to decrease the standard deviation as well which affect our model if we didn't do so."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Data That are Categorical\n",
        "The main reason is to see whether there are any categorical variables that needs feature engineering."
      ],
      "metadata": {
        "id": "a7anUEa6IHpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_cat = ['Pclass', 'Sex', 'Ticket', 'Embarked', 'Cabin', 'CabinCode', 'GroupSize', 'HasCabin']\n",
        "\n",
        "fig, ax = plt.subplots(nrows=len(titanic_cat), figsize=[7, len(titanic_cat)*5])\n",
        "\n",
        "for i, col in enumerate(titanic_cat):\n",
        "    sns.countplot(titanic_all[col], linewidth=0, ax=ax[i])\n",
        "    ax[i].set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "68X0QH0NK0Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cabin and Ticket Columns need feature engineering because the data is too vary for the machine or even humans to interpret."
      ],
      "metadata": {
        "id": "mw9HSxwVAb68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Other Feature\n",
        "This part is for finding which feature that correlates to the survivality"
      ],
      "metadata": {
        "id": "Vlq1OcUBBT1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count Plot Survival Based On Sex"
      ],
      "metadata": {
        "id": "RdOHzRtvLr8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot counting survival based on sex\n",
        "fig, ax = plt.subplots(nrows=2, figsize=(10, 10))\n",
        "\n",
        "sns.countplot(x='Sex', hue='Survived', data=titanic_train, ax=ax[0])\\\n",
        "              .set(title='Survived Count based on Sex')\n",
        "\n",
        "sns.barplot(x='Sex', y='Survived', data=titanic_train, ax=ax[1])\\\n",
        "              .set(title='Survived Count based on Sex')\n",
        "plt.show()\n",
        "\n",
        "# male and female survivability compare to each own gender\n",
        "\n",
        "# (percentage how many female survived from all female passengers)\n",
        "# female_percentage = female_survived.sum / female_passengers.count \n",
        "\n",
        "# (percentage how many male survived from all male passengers)\n",
        "# male_percentage = male_survived.sum / female_passengers.count\n",
        "\n",
        "display(pd.pivot_table(data=titanic_train,\n",
        "               index='Sex',\n",
        "               aggfunc={'Survived': np.mean}))\n",
        "\n",
        "# male and female survivability percentage based compare to all passengers \n",
        "len_data = len(titanic_train)\n",
        "\n",
        "bool_survived = titanic_train['Survived'] == 1\n",
        "bool_not_survived = titanic_train['Survived'] == 0\n",
        "\n",
        "bool_male = titanic_train['Sex'] == 'male'\n",
        "bool_female = titanic_train['Sex'] == 'female'\n",
        "\n",
        "bool_male_survived = titanic_train.loc[bool_survived & bool_male]\n",
        "bool_male_not_survived = titanic_train.loc[bool_not_survived & bool_male]\n",
        "\n",
        "bool_female_survived = titanic_train.loc[bool_survived & bool_female]\n",
        "bool_female_not_survived = titanic_train.loc[bool_not_survived & bool_female]\n",
        "\n",
        "# (percentage how many male survived from all passengers)\n",
        "print('Male Survived Percentage', '{0:.4g}'.format(len(bool_male_survived)/len_data*100), '%')\n",
        "# (percentage how many male not survived from all passengers)\n",
        "print('Male Not Survived Percentage', '{0:.4g}'.format(len(bool_male_not_survived)/len_data*100), '%\\n')\n",
        "# (percentage how many female survived from all passengers)\n",
        "print('Female Survived Percentage', '{0:.4g}'.format(len(bool_female_survived)/len_data*100), '%')\n",
        "# (percentage how many female not survived from all passengers)\n",
        "print('Female Not Survived Percentage', '{0:.4g}'.format(len(bool_female_not_survived)/len_data*100), '%')\n",
        "\n"
      ],
      "metadata": {
        "id": "VbPLQ2eMNBAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_train.head()"
      ],
      "metadata": {
        "id": "ZuQQIS5UzFKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot, we can conclude that female has a higher chance of surviving in the titanic accident.\n",
        "\n",
        "**From female passenger** *74,2%* survived the accident rather than **all male** which has a percentage of *18%*.\n",
        "\n",
        "**From all passengers**:\n",
        "1. *12.23%* of passengers which are **male survived**\n",
        "1. *52.53%* of passengers which are **male not survived**\n",
        "1. *26.15%* of passengers which are **female survived**\n",
        "1. *9.09%* of passengers which are **female not survived**\n"
      ],
      "metadata": {
        "id": "pu5M_mcxS64Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heat Map Survived vs Pclass Columns"
      ],
      "metadata": {
        "id": "pHhDBENw8p-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2YHQGsYnMfjg"
      },
      "outputs": [],
      "source": [
        "# Create a heat map Survived vs Pclass Columns\n",
        "grouped_by_survived_pclass = titanic_all.groupby(['Pclass', 'Survived'])\n",
        "\n",
        "# convert index survived to a column using unstack()\n",
        "print(grouped_by_survived_pclass.size().unstack())\n",
        "\n",
        "sns.heatmap(grouped_by_survived_pclass.size().unstack(), annot=True, fmt='d')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "People on the first class has the highest chance of survivability."
      ],
      "metadata": {
        "id": "6CJsEIyiD326"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Countplot Sex vs Survived With Hue Pclass"
      ],
      "metadata": {
        "id": "1AiFKg5DF7H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Sex',\n",
        "            hue='Pclass',\n",
        "            y='Survived', \n",
        "            data=titanic_all)"
      ],
      "metadata": {
        "id": "C6AaI5zM89AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see female at the first class (Pclass=1) has the highest chance of survivability. While male at the third class has the lowest chance of survivability. So far, female on the first class has the highest chance of survivability.\n"
      ],
      "metadata": {
        "id": "WtSLrHKH8V8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Histplot Age vs Survived"
      ],
      "metadata": {
        "id": "U7CxxS1oH7eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histplot Age vs Survived\n",
        "plt.figure(figsize=[8,7])\n",
        "plt.title('People Survived Based on Age')\n",
        "sns.histplot(x='Age',\n",
        "            data=titanic_all,\n",
        "            hue='Survived',\n",
        "            multiple='stack',\n",
        "            bins=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hEtjJxINIF8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.violinplot(x =\"Sex\", y =\"Age\", hue =\"Survived\",\n",
        "data = titanic_all, split = True)"
      ],
      "metadata": {
        "id": "sNkZmgKCg68X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see reasonable age that mostly survived the titanic is in range 20-30. People with younger age tend to survive rather that the old people.\n",
        "\n",
        "Female in range of 20-45 years has high chance or survival. Male Children has a high chance of survival."
      ],
      "metadata": {
        "id": "2EtIwzrif1ZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on https://med.libretexts.org/Courses/American_Public_University/APUS%3A_An_Introduction_to_Nutrition_(Byerley)/Text/12%3A_Maternal_Infant_Childhood_and_Adolescent_Nutrition/12.02%3A_The_Human_Life_Cycle#:~:text=The%20major%20stages%20of%20the%20human%20lifecycle%20include%20pregnancy%2C%20infancy,age%2C%20and%20the%20senior%20years.\n",
        "\n",
        "The major stages in human lifecycle are defined as follows:\n",
        "1. Pregnancy. The development of a zygote into an embryo and then into a fetus in preparation for childbirth (**Won't be used**).\n",
        "2. Infancy: 0-1 year\n",
        "3. Toddler years: 2 - 3 years\n",
        "4. Childhood: 4 - 8 years \n",
        "5. Puberty: 9 - 13 years\n",
        "6. Older adolescence: 14 - 18 years\n",
        "7. Adulthood: 19 - 30 years\n",
        "8. Middle age: 31 - 50 years\n",
        "9. Senior years: >= 51 years"
      ],
      "metadata": {
        "id": "Vyun-_n75yv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stages = ['infancy', 'toddler', 'childhood', 'puberty', 'older adolescence', \n",
        "          'adulthood', 'middle age', 'senior years']\n",
        "\n",
        "def grouped_ages(data):\n",
        "  if data <= 1:\n",
        "    return 'infancy'\n",
        "  elif data <= 3:\n",
        "    return 'toddler'\n",
        "  elif data <= 8:\n",
        "    return 'childhood'\n",
        "  elif data <= 13:\n",
        "    return 'puberty'\n",
        "  elif data <= 18:\n",
        "    return 'older adolescence'\n",
        "  elif data <= 30:\n",
        "    return 'adulthood'\n",
        "  elif data <= 50:\n",
        "    return 'middle age' \n",
        "  else:\n",
        "    return 'senior years'\n",
        "\n",
        "\n",
        "titanic_all['AgeCategory'] = titanic_all['Age'].apply(grouped_ages)\n",
        "titanic_train['AgeCategory'] = titanic_train['Age'].apply(grouped_ages)\n",
        "titanic_test['AgeCategory'] = titanic_test['Age'].apply(grouped_ages)\n"
      ],
      "metadata": {
        "id": "rviZAtUO7GfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10, 5])\n",
        "sns.barplot(x='AgeCategory', y='Survived', hue='Sex', data=titanic_all)\n",
        "plt.xticks(rotation=30)"
      ],
      "metadata": {
        "id": "a4mW481qSZYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see Female has the highest chance of being survived especially infancy(<=1) and senior (>50). For Male, toddler and infancy has high chance of surviving the accident. "
      ],
      "metadata": {
        "id": "8tjKiMe2_zv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Histplot Embarked vs Survived"
      ],
      "metadata": {
        "id": "WzOCa88QgXVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[8,5])\n",
        "plt.title('People Who Survived Based on Embarked')\n",
        "sns.countplot(x='Embarked', data=titanic_all, hue='Survived')"
      ],
      "metadata": {
        "id": "vJLbHnKSmuRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=titanic_all, \n",
        "            hue='Embarked', \n",
        "            x='Sex', \n",
        "            y='Survived')"
      ],
      "metadata": {
        "id": "54E0Oa0JgelS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "female who embarked from C has higher percentage for surviving the titanic accident"
      ],
      "metadata": {
        "id": "4Kc3e50JXi0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Factor Plot Correlation of Survivability From Traveling with Accompanied or Not."
      ],
      "metadata": {
        "id": "puWMtD16Zkdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92qFbbgwMfjg"
      },
      "outputs": [],
      "source": [
        "# Adding new column 'Accompanied' which has a meaning if the person travelling alone or not\n",
        "\n",
        "bool_groupsize = titanic_all['GroupSize'] > 1\n",
        "titanic_all['Accompanied'] = 0\n",
        "titanic_all.loc[bool_groupsize, 'Accompanied'] = 1\n",
        "\n",
        "sns.factorplot(x='GroupSize', y='Survived', hue='Sex', data=titanic_all)\\\n",
        ".set(title='GroupSize vs Survived (Hue Sex)')\n",
        "\n",
        "sns.factorplot(x='Accompanied', y='Survived', hue='Sex', data=titanic_all)\\\n",
        ".set(title='Factorplot Accompanied vs Survived (Hue Sex)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.barplot(x='AgeCategory', y='Survived', hue='Accompanied', data=titanic_all)\\\n",
        ".set(title='Barplot Accompanied vs Survived (Hue Sex)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wgWbyDFvLmsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the passnger that are accompanied has high change than those that aren't accompanied"
      ],
      "metadata": {
        "id": "SbFJmZExM-9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, we can conclude that female who is accompanied are proritized in their group to be saved.\n"
      ],
      "metadata": {
        "id": "qU7Cjg6RjlYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar Plot and Histogram Plot on Survivability Based on Fare"
      ],
      "metadata": {
        "id": "R0XHu4YTn0Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Fare into 4 quantile\n",
        "titanic_all['FarePerPersonBins'] = pd.qcut(titanic_all['FarePerPerson'], 4)"
      ],
      "metadata": {
        "id": "6-SUxtp6povR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lBFRzZTKMfjh"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(figsize=(15,15), nrows=2, ncols=1)\n",
        "\n",
        "sns.barplot(x='FarePerPersonBins', y='Survived',\n",
        "            data=titanic_all)\\\n",
        "            .set_title('FarePerPersonBins vs Survived')\n",
        "\n",
        "# ax[1].set_title('Countplot FareBins with Hue of Survived')\n",
        "# sns.countplot(x='FarePerPersonBins', hue='Survived', \n",
        "#               data=titanic_all, ax=ax[1])\n",
        "plt.show()\n",
        "\n",
        "display(pd.pivot_table(titanic_train, index='Survived', columns='Pclass', values='Fare', aggfunc='mean'))\n",
        "display(pd.pivot_table(titanic_train, index='Survived', columns='Pclass', values='Fare', aggfunc='median'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "People who pay a lot for the ticket has a high survival rate. We can see that the mean for each people who survived has a higher Fare than those who not survived."
      ],
      "metadata": {
        "id": "0IpcSwgJtGfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Survivability Based on Ticket"
      ],
      "metadata": {
        "id": "Ifguqk_2fxEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnUyBcMoMfji"
      },
      "outputs": [],
      "source": [
        "titanic_all['TicketCode'] = titanic_all['Ticket'].apply(lambda x: x.split(' ')[0].replace('.', '').replace('/', ''))\\\n",
        "    .apply(lambda x: 'n' if x.isnumeric() else x)\\\n",
        "    .str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sort(titanic_all['TicketCode'].unique())\n",
        "tickets_type = ['a', 'c', 'fa', 'fc', 'line', 'n', 'p', 'sc', \n",
        "                'so', 'sp', 'sotono', 'sp','stono', 'sw', 'w']\n",
        "\n",
        "for t in tickets_type:\n",
        "  titanic_all.loc[titanic_all['TicketCode'].str.match(f'^({t}.*)'), 'TicketCode'] = t\n"
      ],
      "metadata": {
        "id": "i3ufENAVvslS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all['TicketCode'].unique()"
      ],
      "metadata": {
        "id": "ag9lnpk8aA78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "7fr383yuMfji"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.histplot(x='TicketCode', hue='Sex', data=titanic_all)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.barplot(x='TicketCode', y='Survived', data=titanic_all)\n",
        "plt.show()\n",
        "\n",
        "# display(pd.pivot_table(titanic_train, index='TicketCode', columns='Survived', values='PassengerId', aggfunc='count'))\n",
        "# display(pd.pivot_table(titanic_train, index='TicketCode', columns='Survived', values='Fare', aggfunc='mean'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-MiKiaMfji"
      },
      "source": [
        "Looks like ticket code didn't provide enough evidence whether those with expensive ticket fare survive the titanic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96AKvkUTMfjj"
      },
      "outputs": [],
      "source": [
        "# titanic_all['CabinCode'] = titanic_train['Cabin'].apply(lambda x: str(x).split(' ')[0][0]).str.lower()\n",
        "# titanic_all['CabinCount'] = titanic_train['Cabin'].apply(lambda x: len(str(x).split(' ')))\n",
        "titanic_all.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "AQPZZrMdMfjj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10,8])\n",
        "plt.title('Survived vs HasCabin')\n",
        "sns.countplot(x='HasCabin', data=titanic_train, hue='Survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZaWZXQpMMfjj"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=[10,8])\n",
        "# plt.title('Survived vs Cabin Count')\n",
        "# sns.countplot(x='CabinCount', data=titanic_all, hue='Survived')\n",
        "# plt.show()\n",
        "# display(pd.pivot_table(titanic_train, index='Cabin Count', columns='Survived', values='Fare', aggfunc='count'))\n",
        "# display(pd.pivot_table(titanic_train, index='Cabin Count', columns='Survived', values='Fare', aggfunc='mean'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unt68jL_Mfjj"
      },
      "source": [
        "Looks like people with multiple cabins (rich) most likely to survive but this doesn't ensure that. for example 4 cabins (all of them survive maybe they are a VIP that needs to be saved first) but others with 2 and 3 cabin has a slighly little change to survive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "G5g8kLJUMfjj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10,8])\n",
        "plt.title('Survived vs Cabin Count')\n",
        "sns.countplot(x='Parch', data=titanic_all, hue='Survived')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Uh86_Uv5Mfjj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10,8])\n",
        "plt.title('Survived vs Cabin Count')\n",
        "sns.countplot(x='SibSp', data=titanic_all, hue='Survived')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5BzLl11Mfjk"
      },
      "source": [
        "One thing for sure that people who are travelling alone tend to survive because they only need to save themselves without worying others"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Countplot Title vs Survived"
      ],
      "metadata": {
        "id": "ilTdtrQqTrL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPlOsQU0Mfjk"
      },
      "outputs": [],
      "source": [
        "titanic_all['Title'] = titanic_all['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "c-Fi6pxRMfjk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10,5])\n",
        "plt.xticks(rotation=45)\n",
        "sns.countplot(x='Title', hue='Survived',data=titanic_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouped Title that have the same category"
      ],
      "metadata": {
        "id": "VRp2iM-Eh0vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_categorized = {\n",
        "    'Mr': 'Mr',\n",
        "    'Mrs': 'Mrs',\n",
        "    'Mme': 'Mrs',\n",
        "    'Miss': 'Ms',\n",
        "    'Mlle': 'Ms',\n",
        "    'Ms': 'Ms',\n",
        "    'Master': 'Master',\n",
        "    'Capt': 'Officer',\n",
        "    'Col': 'Officer',\n",
        "    'Major': 'Officer',\n",
        "    'Dr': 'Other',\n",
        "    'Rev': 'Other',\n",
        "    'Lady': 'Royalty',\n",
        "    'Sir': 'Royalty',\n",
        "    'the Countess': 'Royalty',\n",
        "    'Jonkheer': 'Royalty',\n",
        "    'Don': 'Royalty',\n",
        "    'Dona': 'Royalty',\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "bWN4YwLUiC5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all['Title'] = titanic_all['Title'].map(title_categorized)"
      ],
      "metadata": {
        "id": "PjQ7jw5Gt6IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10,5])\n",
        "plt.xticks(rotation=45)\n",
        "sns.countplot(x='Title', hue='Survived',data=titanic_all)"
      ],
      "metadata": {
        "id": "DN1FRuxbneLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZRvs5Be-Mfjk"
      },
      "outputs": [],
      "source": [
        "pd.pivot_table(data=titanic_all, index='Title', columns='Pclass',values='Survived', aggfunc='mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zCnpGwwMfjk"
      },
      "source": [
        "We are going to change the title to a number where 'Mr' corresponds to 0, 'Mrs' corresponds to 1, 'Miss' corresponds to 2, 'Master' corresponds to 3 and others corresponds to 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSogi0z6Mfjl"
      },
      "source": [
        "# Feature Engineering "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFIX2m1sMfjl"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all_feat_eng = titanic_all.copy()"
      ],
      "metadata": {
        "id": "tdbog7P10QWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all_feat_eng.head()"
      ],
      "metadata": {
        "id": "bphdPS93qgD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_all_feat_eng.info()"
      ],
      "metadata": {
        "id": "LEYSjG9OEV73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns to be deleted because it is to vary\n",
        "cols_to_be_deleted = ['PassengerId', 'Name', 'Cabin', 'Ticket']\n",
        "for col in cols_to_be_deleted:\n",
        "  if col in titanic_all_feat_eng.columns:\n",
        "    titanic_all_feat_eng.drop(columns=col, inplace=True)\n",
        "\n",
        "# Collect Columns that are Object or Category datatype to be encoded\n",
        "col_obj_or_cat = []\n",
        "for col in titanic_all_feat_eng.columns:\n",
        "  if (titanic_all_feat_eng[col].dtype == 'object' or\n",
        "      titanic_all_feat_eng[col].dtype == 'category'):\n",
        "    col_obj_or_cat.append(col)\n",
        "\n",
        "\n",
        "for col in col_obj_or_cat:\n",
        "  print(col, titanic_all_feat_eng[col].unique())"
      ],
      "metadata": {
        "id": "8odwTDujEAa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace String or Object data dype features with numbers\n",
        "title = {\n",
        "    'Master': 0, \n",
        "    'Mr': 1, \n",
        "    'Mrs': 2, \n",
        "    'Miss': 3,\n",
        "    }\n",
        "\n",
        "# each age category is mapped to an integer value where the younger the person\n",
        "# the lower their integer value. While for the older is the opposite. \n",
        "age_category = {\n",
        "    'infancy': 0,\n",
        "    'toddler':1,\n",
        "    'childhood':2,\n",
        "    'puberty':3,\n",
        "    'older adolescence': 4,\n",
        "    'adulthood':5,\n",
        "    'middle age': 6,\n",
        "    'senior years':7,\n",
        "    }\n",
        "\n",
        "fare_per_person_bins = {\n",
        "    '(-0.001, 7.55]' : 0,\n",
        "    '(7.55, 8.05]'   : 1,\n",
        "    '(8.05, 15.0]'   : 2,\n",
        "    '(15.0, 128.082]': 3,\n",
        "    }\n",
        "\n",
        "\n",
        "def encode_title(data):\n",
        "  \"\"\"encode Title column data\"\"\"\n",
        "  if data in title.keys():\n",
        "    return title[data]\n",
        "  else:\n",
        "    return len(title)\n",
        "\n",
        "def encode_age_category(data):\n",
        "  \"\"\"encode AgeCategory column data\"\"\"\n",
        "  if data in age_category.keys():\n",
        "    return age_category[data]\n",
        "\n",
        "def encode_fare_per_person_bins(data):\n",
        "  \"\"\"encode FarePerPersonBins column data\"\"\"\n",
        "  data = str(data)\n",
        "  if data in fare_per_person_bins.keys():\n",
        "    return fare_per_person_bins[data]"
      ],
      "metadata": {
        "id": "lUYrCMDbwuP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "if titanic_all_feat_eng['Title'].dtype == 'O':\n",
        "  titanic_all_feat_eng['Title'] = \\\n",
        "  titanic_all_feat_eng['Title'].apply(encode_title)\n",
        "  print('done encode Title')\n",
        "  display(titanic_all_feat_eng['Title'].unique())\n",
        "\n",
        "if titanic_all_feat_eng['AgeCategory'].dtype == 'O':\n",
        "  titanic_all_feat_eng['AgeCategory'] = \\\n",
        "  titanic_all_feat_eng['AgeCategory'].apply(encode_age_category)\n",
        "  print('done encode AgeCategory')\n",
        "  display(titanic_all_feat_eng['AgeCategory'].unique())\n",
        "\n",
        "if titanic_all_feat_eng['FarePerPersonBins'].dtype == 'category':\n",
        "  titanic_all_feat_eng['FarePerPersonBins'] = \\\n",
        "  titanic_all_feat_eng['FarePerPersonBins'].apply(encode_fare_per_person_bins)\n",
        "  print('done encode FarePerPersonBins')\n",
        "  titanic_all_feat_eng['FarePerPersonBins'] = \\\n",
        "  titanic_all_feat_eng['FarePerPersonBins'].astype('int64')\n",
        "  display(titanic_all_feat_eng['FarePerPersonBins'].unique())\n",
        "\n",
        "titanic_all_feat_eng['Sex'] = \\\n",
        "encoder.fit_transform(titanic_all_feat_eng['Sex'])\n",
        "print(titanic_all_feat_eng['Sex'].unique())\n",
        "\n",
        "titanic_all_feat_eng['Embarked'] = \\\n",
        "encoder.fit_transform(titanic_all_feat_eng['Embarked'])\n",
        "print(titanic_all_feat_eng['Embarked'].unique())\n",
        "\n",
        "titanic_all_feat_eng['CabinCode'] = \\\n",
        "encoder.fit_transform(titanic_all_feat_eng['CabinCode'])\n",
        "print(titanic_all_feat_eng['CabinCode'].unique())\n",
        "\n",
        "titanic_all_feat_eng['TicketCode'] = \\\n",
        "encoder.fit_transform(titanic_all_feat_eng['TicketCode'])\n",
        "print(titanic_all_feat_eng['TicketCode'].unique())\n",
        "\n",
        "display(titanic_all_feat_eng.head())\n",
        "display(titanic_all_feat_eng.info())\n",
        "\n"
      ],
      "metadata": {
        "id": "EdnRinWyZvdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temp = titanic_all_feat_eng[['Survived', 'Pclass', 'Age','Sex', 'SibSp', 'Parch', 'Embarked', 'CabinCode', 'HasCabin', 'FamilySize', 'FriendSize', 'GroupSize', 'AgeCategory', 'Accompanied', 'FarePerPersonBins', 'TicketCode', 'train_test', 'Title']]\n",
        "temp = titanic_all_feat_eng\n",
        "# temp_train = temp[temp['train_test']==0].drop(columns=['train_test'])\n",
        "temp_train = temp[temp['train_test']==0].drop(columns=['train_test'])\n",
        "\n",
        "\"\"\"scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "temp_train_stan_scaled = scaler.fit_transform(temp_train)\n",
        "temp_train_stan_scaled_df = pd.DataFrame(data=temp_train_scaled, \n",
        "columns=['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', \n",
        "'CabinCode', 'HasCabin', 'FamilySize', 'FriendSize', 'GroupSize', \n",
        "'AgeCategory', 'Accompanied', 'FarePerPersonBins', 'TicketCode','Title'])\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"temp_train_minmax_scaled = minmax_scaler.fit_transform(temp_train)\n",
        "temp_train_minmax_scaled_df = pd.DataFrame(data=temp_train_minmax_scaled, \n",
        "columns=['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', \n",
        "'CabinCode', 'HasCabin', 'FamilySize', 'FriendSize', 'GroupSize', \n",
        "'AgeCategory', 'Accompanied', 'FarePerPersonBins', 'TicketCode','Title'])\n",
        "\"\"\"\n",
        "\n",
        "# for col in temp_train.columns:\n",
        "#   plt.figure(figsize=(20,10))\n",
        "#   sns.histplot(x=col, bins=10, data=temp_train)\n",
        "#   plt.show()\n",
        "mask = np.tril(np.ones_like(temp_train.corr()))\n",
        "# print(mask)\n",
        "plt.figure(figsize=(20,15))\n",
        "sns.heatmap(temp_train.corr(), annot=True, mask=mask, cmap='YlGnBu')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gjRRyp3UDXjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the heatmap we can see corellation amongst features and we can see that there is a high corelation between:\n",
        "1. **SibSp**, **Parch** with **FamilySize** (about 89% and 78%) because the feature itself (**FamilySize**) is determined by number of family (sibling, spouse, parent, child, etc.) that is travelling with the passenger.\n",
        "2. **FriendSize** and **FamilySize** with **GroupSize** (97% and 86%) because **GroupSize** sumarizes how many persons that travelled with the passenger (max(**FriendSize**, **FamilySize**)).\n",
        "3. **Age** and **AgeCategory** because the value will increase as the passnger is older (about 88%)\n",
        "4. (**Fare**, **FarePerPerson**, **HasCabin**, **FarePerPersonBins**) and **Pclass**. This is very spot due to social economy status that Pclass (high class) pay a 'first class' ticket which is expensive. High class people tend to buy ticket that includes cabin.\n",
        "5. **Sex** and **Title** (-79%) because titles are based on gender.\n",
        "\n",
        "Corelation alaysis is useful to determine which feature to use because there's a lot of features shown above. We can choose which feature that has a high correlation with the target variable or class ('Survived' feature). Which in this example are 'Sex' or 'Title' (high correlated), 'Pclass', 'HasCabin', and 'Accompanied'.\n",
        "\n"
      ],
      "metadata": {
        "id": "eRXEUlODK3NX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "Rc8sAEVzvA4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
      ],
      "metadata": {
        "id": "Xgwz2E3sfAlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]\\\n",
        "[['Sex', 'Pclass', 'HasCabin', 'Fare', 'GroupSize']]\n",
        "y = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]['Survived']\n",
        "\n",
        "# Submission\n",
        "X_submit = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 1]\\\n",
        "[['Sex', 'Pclass', 'HasCabin', 'Fare', 'GroupSize']]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splot the data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, \n",
        "    random_state=42, stratify=y,\n",
        "    )\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "fN6f8FsPz7nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad8tr6VpMfjm"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "          RandomForestClassifier(random_state=41), \n",
        "          KNeighborsClassifier(), \n",
        "          SVC(random_state=41), \n",
        "          LogisticRegression(random_state=41), \n",
        "          DecisionTreeClassifier(random_state=41),\n",
        "          XGBClassifier(random_state=41),\n",
        "          GaussianNB(),\n",
        "          ]\n",
        "\n",
        "df_models = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
        "\n",
        "for m in models:\n",
        "    m.fit(X_train, y_train)\n",
        "    df_models = df_models.append({\n",
        "        'Model': m.__class__.__name__, \n",
        "        'Accuracy': m.score(X_test, y_test)\n",
        "        },\n",
        "      ignore_index=True,\n",
        "      )\n",
        "\n",
        "df_models.sort_values(by='Accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning "
      ],
      "metadata": {
        "id": "NCCBe8QSvFPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "metadata": {
        "id": "c4coPg6KzPPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Model"
      ],
      "metadata": {
        "id": "fy9WWymgtUZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]\\\n",
        "[['Sex', 'Pclass', 'HasCabin', 'Fare', 'GroupSize']]\n",
        "y = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]['Survived']\n",
        "\n",
        "# Submission\n",
        "X_submit = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 1]\\\n",
        "[['Sex', 'Pclass', 'HasCabin', 'Fare', 'GroupSize']]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splot the data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "6xLeDbWdUXKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abTJ1Q8iMfjm"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(random_state=41)\n",
        "rf_parameters = {\n",
        "     'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
        "     'max_features': ['auto', 'sqrt'],\n",
        "     'min_samples_leaf': [1, 2, 3, 4],\n",
        "     'min_samples_split': [2, 5, 10],\n",
        "     'n_estimators': [50,100, 200, 400, 600, 800, 1000]\n",
        "}\n",
        "\n",
        "model_cv = RandomizedSearchCV(rf_model, param_distributions=rf_parameters, cv=10, scoring='accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd2xj4YBMfjm"
      },
      "outputs": [],
      "source": [
        "model_cv.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cal_confusion_matrix(np.array(y_test).astype(int), np.array(model_cv.best_estimator_.predict(X_test).astype(int)))"
      ],
      "metadata": {
        "id": "h8DWFJACC2J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[tn, fp],\n",
        "# [tp, fn]]\n",
        "\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "tp, fp, fn, tn = cm[1][0], cm[0][1], cm[1][1], cm[0][0] "
      ],
      "metadata": {
        "id": "4mpkzKZfD2T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDQfzc6WMfjm"
      },
      "outputs": [],
      "source": [
        "# np.array(y_test)\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_cv.best_estimator_.classes_).plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tp/ (tp+fp)\n",
        "recall = tp/ (tp+fn)\n",
        "\n",
        "print(\"precision = \", precision)\n",
        "print(\"recall = \", recall)\n",
        "print(\"Recall is bad we need to enchance it\")"
      ],
      "metadata": {
        "id": "tu9RrBzWIydD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVyqVr31Mfjn"
      },
      "outputs": [],
      "source": [
        "model_cv.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCVon8BNMfjn"
      },
      "outputs": [],
      "source": [
        "prediction = model_cv.best_estimator_.predict(X_submit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cyn5tEfMfjn"
      },
      "outputs": [],
      "source": [
        "submit = pd.DataFrame({'PassengerId': titanic_test['PassengerId'], 'Survived': prediction.astype(int)}).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.head()"
      ],
      "metadata": {
        "id": "zBI1_fltyXm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XHkMrJjKMfjn"
      },
      "outputs": [],
      "source": [
        "# store data in csv file\n",
        "submit.to_csv('rf_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77uvM4njMfjn"
      },
      "outputs": [],
      "source": [
        "# download csv from colab\n",
        "from google.colab import files\n",
        "\n",
        "files.download('rf_submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test score on the kaggle competition is 0.676 for Random Forest model (**IF TRAINED USING X_train and y_train**)"
      ],
      "metadata": {
        "id": "T0wcZIEU2Kot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It obtained score of 0.77271 in the Kaggle contest. **IF we use all the training data set for model training (X, Y)** not using X_train and y_train"
      ],
      "metadata": {
        "id": "LgXXXwfbYvVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Model"
      ],
      "metadata": {
        "id": "Pjc99h1Dtaeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]\\\n",
        "[['Sex', 'Pclass', 'HasCabin', 'Fare', 'GroupSize']]\n",
        "y = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]['Survived']\n",
        "\n",
        "# Submission\n",
        "X_submit = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 1]\\\n",
        "[['Sex', 'Pclass', 'HasCabin', 'Fare', 'GroupSize']]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splot the data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "tZYqZltFk4un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model = DecisionTreeClassifier(random_state=41)\n",
        "dt_parameters = {\n",
        "    'max_depth': [2, 3, 5, 10, 20],\n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
        "    'criterion': [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "model_cv = RandomizedSearchCV(dt_model, param_distributions=dt_parameters, cv=10, scoring='f1')\n"
      ],
      "metadata": {
        "id": "OQ87N4xAtdK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cv.fit(X, y)"
      ],
      "metadata": {
        "id": "Cz7bi95nvxOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[tn, fp],\n",
        "# [tp, fn]]\n",
        "\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "tp, fp, fn, tn = cm[1][0], cm[0][1], cm[1][1], cm[0][0] "
      ],
      "metadata": {
        "id": "oV22xP9jv5-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.array(y_test)\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_cv.best_estimator_.classes_).plot()\n"
      ],
      "metadata": {
        "id": "4kcm40Xiv-7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tp/ (tp+fp)\n",
        "recall = tp/ (tp+fn)\n",
        "\n",
        "print(\"precision = \", precision)\n",
        "print(\"recall = \", recall)\n",
        "print(\"Recall is bad we need to enchance it\")"
      ],
      "metadata": {
        "id": "q5MaAE6fv_CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cv.best_score_"
      ],
      "metadata": {
        "id": "XW0m3Kpuv_GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_cv.best_estimator_.predict(X_submit)"
      ],
      "metadata": {
        "id": "TISez1Rcv_Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.DataFrame({'PassengerId': titanic_test['PassengerId'], 'Survived': prediction.astype(int)}).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "c9qPVv-fwF8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store data in csv file\n",
        "submit.to_csv('dt_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "SK6SA7vqwGBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download csv from colab\n",
        "from google.colab import files\n",
        "\n",
        "files.download('dt_submission.csv')"
      ],
      "metadata": {
        "id": "1-trB7ncwGEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test score on the kaggle competition is 0.622 for Random Forest model"
      ],
      "metadata": {
        "id": "h4m-c6exwMHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It obtained score of 0.73444 in the Kaggle contest. **IF we use all the training data set for model training (X, Y)** not using X_train and y_train"
      ],
      "metadata": {
        "id": "whBkp-zjYsZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Classifier"
      ],
      "metadata": {
        "id": "NSKinPeWwU_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to use different feature"
      ],
      "metadata": {
        "id": "PFpiV_TpUHIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]\\\n",
        "[['Sex', 'Pclass', 'Fare', 'Embarked', 'Age', 'SibSp', 'Parch']]\n",
        "y = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]['Survived']\n",
        "\n",
        "# Submission\n",
        "X_submit = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 1]\\\n",
        "[['Sex', 'Pclass', 'Fare', 'Embarked', 'Age', 'SibSp', 'Parch']]\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splot the data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "iprQ7SJvUFT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_model = SVC(random_state=41)\n",
        "svc_parameters = {\n",
        "    'kernel' : ['linear', 'rbf', 'poly',  'sigmoid'],\n",
        "    'gamma': [0.1, 1, 10, 100],\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "}\n",
        "model_cv = RandomizedSearchCV(svc_model, param_distributions=svc_parameters, cv=10, scoring='f1')"
      ],
      "metadata": {
        "id": "x5NBu-tewVnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cv.fit(X, y)"
      ],
      "metadata": {
        "id": "cAV66A3MSGfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.array(y_test)\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_cv.best_estimator_.classes_).plot()\n"
      ],
      "metadata": {
        "id": "jB51qP311Efm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[tn, fp],\n",
        "# [tp, fn]]\n",
        "\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "tp, fp, fn, tn = cm[1][0], cm[0][1], cm[1][1], cm[0][0] "
      ],
      "metadata": {
        "id": "bAHYNT5WT6l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tp/ (tp+fp)\n",
        "recall = tp/ (tp+fn)\n",
        "\n",
        "print(\"precision = \", precision)\n",
        "print(\"recall = \", recall)\n",
        "print(\"Recall is bad we need to enchance it\")"
      ],
      "metadata": {
        "id": "qJ_lrHcnTs0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('f1 score = ', model_cv.best_score_)\n",
        "print('accuracy score = ', accuracy_score(y_test, model_cv.best_estimator_.predict(X_test)))"
      ],
      "metadata": {
        "id": "uz8EzVFgTs5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_cv.best_estimator_.predict(X_submit)\n",
        "submit = pd.DataFrame({'PassengerId': titanic_test['PassengerId'], 'Survived': prediction.astype(int)}).reset_index(drop=True)\n",
        "# store data in csv file\n",
        "submit.to_csv('svc_submission.csv', index=False)\n",
        "# download csv from colab\n",
        "from google.colab import files\n",
        "\n",
        "files.download('svc_submission.csv')"
      ],
      "metadata": {
        "id": "AVz52hZ2Ts8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It obtained score of 0.7751 in the Kaggle contest. **IF we use all the training data set for model training (X, Y)** not using X_train and y_train\n",
        " "
      ],
      "metadata": {
        "id": "Cp8vGySAXVts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "QNXeVPH0XCZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]\\\n",
        "[['Sex', 'Pclass', 'Fare', 'Embarked', 'Age', 'SibSp', 'Parch']]\n",
        "y = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 0]['Survived']\n",
        "\n",
        "# Submission\n",
        "X_submit = titanic_all_feat_eng[titanic_all_feat_eng['train_test'] == 1]\\\n",
        "[['Sex', 'Pclass', 'Fare', 'Embarked', 'Age', 'SibSp', 'Parch']]\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splot the data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "Xiw6r4Q75mWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(random_state=41)\n",
        "lr_parameters = {\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C': [100, 10, 1.0, 0.1, 0.01],\n",
        "    }\n",
        "model_cv = RandomizedSearchCV(lr_model, param_distributions=lr_parameters, cv=10, scoring='f1')"
      ],
      "metadata": {
        "id": "__DBJxUTs-xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iZwCY37_tPzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_cv.best_estimator_.classes_).plot()\n"
      ],
      "metadata": {
        "id": "SCl7XEIx6u-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[tn, fp],\n",
        "# [tp, fn]]\n",
        "\n",
        "cm = confusion_matrix(np.array(y_test), np.array(model_cv.best_estimator_.predict(X_test)))\n",
        "tp, fp, fn, tn = cm[1][0], cm[0][1], cm[1][1], cm[0][0] "
      ],
      "metadata": {
        "id": "Fw8jizvY7TQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tp/ (tp+fp)\n",
        "recall = tp/ (tp+fn)\n",
        "\n",
        "print(\"precision = \", precision)\n",
        "print(\"recall = \", recall)\n",
        "print(\"Recall is bad we need to enchance it\")"
      ],
      "metadata": {
        "id": "EEZ09x2R73yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('f1 score = ', model_cv.best_score_)\n",
        "print('accuracy score = ', accuracy_score(y_test, model_cv.best_estimator_.predict(X_test)))"
      ],
      "metadata": {
        "id": "5zsu4o3D736v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_cv.best_estimator_.predict(X_submit)\n",
        "submit = pd.DataFrame({'PassengerId': titanic_test['PassengerId'], 'Survived': prediction.astype(int)}).reset_index(drop=True)\n",
        "# store data in csv file\n",
        "submit.to_csv('lr_submission.csv', index=False)\n",
        "# download csv from colab\n",
        "from google.colab import files\n",
        "\n",
        "files.download('lr_submission.csv')"
      ],
      "metadata": {
        "id": "_rLB4SeW739_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pNq0zQQU74BM"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Titanic Third.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}